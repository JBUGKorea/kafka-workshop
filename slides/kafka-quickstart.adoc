== Kafka QuickStart

* Kafka 실습
* http://kafka.apache.org/quickstart
* This hands-on is based on Kafka 1.1.1.
* Confluent Open Source 4.1.1

=== Prerequisites

* JDK 8

== Download Kafka

* Kafka를 다운로드하고 설치합니다.
* https://www.apache.org/dyn/closer.cgi?path=/kafka/1.1.0/kafka_2.11-1.1.0.tgz

[source,sh]
----
tar -xzf kafka_2.11-1.1.0.tgz
cd kafka_2.11-1.1.0
----

== Start Zookeeper

* Zookeeper를 실행합니다.

[source,sh]
----
cd kafka_2.11-1.1.0
bin/zookeeper-server-start.sh config/zookeeper.properties
----


== Start Kafka Broker

* Kafka broker 설정 업데이트 후 실행합니다.
** config/server.properties 에 hostname을 명시해줍니다.
** NOTE: confluent 는 <CONFLUENT_HOME>/etc/kafka/server.properties

[source,sh]
----
cd kafka_2.11-1.1.0

vim config/server.properties
listeners=PLAINTEXT://127.0.0.1:9092

bin/kafka-server-start.sh config/server.properties
----


== Create a topic

* test topic을 생성합니다.
* Note: parition 1 이라면 메세지 순서가 보장된다. (당연한 소리)

[source,sh]
----
cd kafka_2.11-1.1.0
bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test

bin/kafka-topics.sh --list --zookeeper localhost:2181
----

== Check zookeeper znode (Optional)

* Zookeeper node에 생성된 kafka broker 정보를 확인해봅니다.
* 먼저 Zookeeper 를 다운로드하고 설치합니다.
** Downalod Zookeeper http://mirror.navercorp.com/apache/zookeeper/stable/
* http://zookeeper.apache.org/doc/r3.4.13/zookeeperStarted.html
* http://epicdevs.com/23?category=460351

[source,sh]
----
cd zookeeper-3.4.12
bin/zkCli.sh -server 127.0.0.1:2181

ls /
ls /brokers
ls /brokers/ids

get /brokers/ids
get /brokers/ids/0

ls /brokers/topics
ls /brokers/topics/test
ls /brokers/topics/test/partitions
ls /brokers/topics/test/partitions/0
ls /brokers/topics/test/partitions/0/state
get /brokers/topics/test/partitions/0/state
----

== Why Zookeeper

* Zookeeper 가 필요한 이유
* Distributed Consensus Algorithm 구현 필요
* 시스템 간의 락, 설정 공유, 리더 선출, atomic 한 연산등 구현이 필요
** https://www.confluent.io/blog/distributed-consensus-reloaded-apache-zookeeper-and-replication-in-kafka/
** https://blog.seulgi.kim/2014/05/zookeeper-1-znode-zookeeper-data.html
** https://blog.seulgi.kim/2014/05/zookeeper-0-zookeepr.html

== Producing some messages

* Console에서 아무 메세지나 producing 해봅니다.

[source,sh]
----
bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test
----


== Start a consumer

* Console에서 consuming 해봅니다.

[source,sh]
----
bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginning
----


== Setting up a multi-broker cluster

* kafka broker 2개 더 추가합니다. 총 3개
* kafka broker id: 0, 1, 2
* config/server.properties 파일을 복사하여 추가 생성합니다.
** broker.id
** log.dir
* kafka broker 1, 2를 실행합니다.

[source,sh]
----
cp config/server.properties config/server-1.properties
cp config/server.properties config/server-2.properties


config/server-1.properties:
    broker.id=1
    listeners=PLAINTEXT://127.0.0.1:9093
    log.dir=/tmp/kafka-logs-1
 
config/server-2.properties:
    broker.id=2
    listeners=PLAINTEXT://127.0.0.1:9094
    log.dir=/tmp/kafka-logs-2


bin/kafka-server-start.sh config/server-1.properties

bin/kafka-server-start.sh config/server-2.properties
----

== Create a new topic with a replication & partition factor of three

* replica 3 & partition 3 topic을 생성해봅니다.

[source,sh]
----
bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 3 --partitions 3 --topic my-replicated-topic

bin/kafka-topics.sh --describe --zookeeper localhost:2181 --topic my-replicated-topic
----

== Producing & Consuming

[source,sh]
----
bin/kafka-console-consumer.sh --bootstrap-server localhost:9092,localhost:9093,localhost:9094 --from-beginning --topic my-replicated-topic

bin/kafka-console-producer.sh --broker-list localhost:9092,localhost:9093,localhost:9094 --topic my-replicated-topic


# kill leader broker
jps -mlvV |grep server.properties
jps | grep server.properties | awk '{print $1}' | xargs kill -15
----

== Use Kafka Streams to process data

* http://kafka.apache.org/11/documentation/streams/quickstart
* 링크로 이동해서 Kafka Stream 기능을 실습해보세요.


== Kafka Connect

* How to import/export data using Kafka Connect

[source,sh]
----
vim config/connect-file-source.properties
file=/tmp/test.txt

echo -e "foo\nbar" > /tmp/test.txt

bin/connect-standalone.sh config/connect-standalone.properties config/connect-file-source.properties config/connect-file-sink.properties


more test.sink.txt

bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic connect-test --from-beginning

bin/kafka-console-producer.sh --broker-list localhost:9092 --topic connect-test
----

